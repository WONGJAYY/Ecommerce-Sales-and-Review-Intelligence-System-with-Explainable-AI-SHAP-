# üß† E-Commerce Sales and Review Intelligence System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![LightGBM](https://img.shields.io/badge/LightGBM-ML-green.svg)](https://lightgbm.readthedocs.io/)
[![SHAP](https://img.shields.io/badge/SHAP-Explainable_AI-orange.svg)](https://shap.readthedocs.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-REST_API-009688.svg)](https://fastapi.tiangolo.com/)
[![Streamlit]([https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B.svg)](https://review-intelligence-system.streamlit.app/)

A production-grade **MLOps platform** for predicting product sales volume and identifying negative review risks with **SHAP-based explainability**. Built with LightGBM for high-performance inference and FastAPI for real-time serving.

---

## üéØ Problem Statement

E-commerce platforms face two critical challenges:

1. **Sales Forecasting**: Predicting which products will sell well to optimize inventory and marketing
2. **Review Risk Management**: Identifying products likely to receive negative reviews before they impact brand reputation

This system addresses both challenges with interpretable ML models that provide actionable insights.

---

## ‚ú® Key Features

| Feature                      | Description                                                 |
| ---------------------------- | ----------------------------------------------------------- |
| üîÆ **Sales Prediction**      | Predict expected sales volume with confidence intervals     |
| ‚ö†Ô∏è **Risk Assessment**       | Identify products with high probability of negative reviews |
| üìä **SHAP Explainability**   | Transparent explanations for every prediction               |
| ‚ö° **Real-time API**         | FastAPI endpoints with <50ms inference time                 |
| üìà **Interactive Dashboard** | Streamlit app for visualization and demos                   |
| üîÑ **Drift Detection**       | Monitor data and model drift in production                  |
| üì¶ **Feature Store**         | Versioned feature management with Parquet persistence       |

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Raw Data   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Ingestion   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Validation  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Training   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Preprocessing‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇSales Predictor‚îÇ   ‚îÇRisk Predictor‚îÇ    ‚îÇ   Registry   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                  ‚îÇ                  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   FastAPI    ‚îÇ
                    ‚îÇ   Serving    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Dashboard   ‚îÇ    ‚îÇ    SHAP      ‚îÇ    ‚îÇ  Monitoring  ‚îÇ
‚îÇ (Streamlit)  ‚îÇ    ‚îÇ Explanations ‚îÇ    ‚îÇ(Drift/Metrics)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ app.py                    # Streamlit dashboard
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml           # Main configuration
‚îÇ   ‚îú‚îÄ‚îÄ features.yaml         # Feature definitions
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml     # Model hyperparameters
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # Raw dataset storage
‚îÇ   ‚îú‚îÄ‚îÄ processed/            # Preprocessed data
‚îÇ   ‚îî‚îÄ‚îÄ features/             # Feature store
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile            # Container definition
‚îú‚îÄ‚îÄ logs/                     # Application logs
‚îú‚îÄ‚îÄ models/                   # Saved model artifacts
‚îÇ   ‚îú‚îÄ‚îÄ sales_predictor/
‚îÇ   ‚îî‚îÄ‚îÄ review_risk_predictor/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ train.py              # Training pipeline script
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/                 # Data layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py      # Data loading & parsing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py     # Data validation checks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py  # Cleaning & transformation
‚îÇ   ‚îú‚îÄ‚îÄ features/             # Feature engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_definitions.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_store.py
‚îÇ   ‚îú‚îÄ‚îÄ models/               # ML models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sales_predictor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ review_risk_predictor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registry.py
‚îÇ   ‚îú‚îÄ‚îÄ explainability/       # SHAP module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ shap_explainer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ explanations.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualization.py
‚îÇ   ‚îú‚îÄ‚îÄ serving/              # API layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.py            # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py      # Inference engine
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py        # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/           # Production monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_drift.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_drift.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Utilities
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ logging.py
‚îî‚îÄ‚îÄ tests/                    # Unit tests
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- pip

### Installation

```bash
# Clone the repository
git clone https://github.com/MuneebMM/Ecommerce-Sales-and-Review-Intelligence-System-with-Explainable-AI-SHAP-.git
cd Ecommerce-Sales-and-Review-Intelligence-System-with-Explainable-AI-SHAP-

# Install dependencies
pip install -r requirements.txt

# Place your dataset in the root directory
# tokopedia_products_with_review.csv
```

### Train Models

```bash
# Train both models
python scripts/train.py --model all --nrows 5000

# Train specific model
python scripts/train.py --model risk --nrows 1000
```

### Start the API Server

```bash
uvicorn src.serving.api:app --host 0.0.0.0 --port 8000
```

### Launch Dashboard

```bash
streamlit run app.py --server.port 8501
```

---

## üì° API Endpoints

| Endpoint                | Method | Description                    |
| ----------------------- | ------ | ------------------------------ |
| `/health`               | GET    | Health check with model status |
| `/v1/predict/sales`     | POST   | Sales volume prediction        |
| `/v1/predict/risk`      | POST   | Review risk assessment         |
| `/v1/model/info/{type}` | GET    | Model information              |
| `/docs`                 | GET    | Swagger documentation          |

### Example: Risk Prediction

```bash
curl -X POST "http://localhost:8000/v1/predict/risk" \
  -H "Content-Type: application/json" \
  -d '{
    "product_id": "SKU123",
    "price": 150000,
    "message_length": 50,
    "word_count": 10
  }'
```

**Response:**

```json
{
  "product_id": "SKU123",
  "risk_probability": 0.15,
  "risk_level": "low",
  "is_high_risk": false,
  "model_version": "v1.0"
}
```

---

## üìä Model Performance

| Model                     | Metric   | Score      |
| ------------------------- | -------- | ---------- |
| **Review Risk Predictor** | AUC-ROC  | 0.84       |
| **Review Risk Predictor** | F1 Score | 0.72       |
| **Sales Predictor**       | R¬≤ Score | 0.68       |
| **Sales Predictor**       | MAE      | 45.2 units |

---

## üîç SHAP Explainability

Every prediction includes interpretable explanations powered by **TreeSHAP**:

- **Feature Importance**: Which factors drive each prediction
- **Waterfall Charts**: Visual breakdown of feature contributions
- **Counterfactuals**: Actionable recommendations for improvement

---

## üõ°Ô∏è Production Monitoring

The system includes comprehensive monitoring:

- **Data Drift Detection**: KS-test and Chi-squared for distribution shifts
- **Model Drift Detection**: PSI (Population Stability Index) tracking
- **Performance Monitoring**: Real-time metric collection (Prometheus-compatible)

---

## üß™ Dataset

This project uses the **Tokopedia Products with Reviews** dataset containing:

- Product information (price, stock, category, shop details)
- Customer reviews (ratings, messages, timestamps)
- ~30,000+ reviews from ~500 products

**Note**: The dataset is not included in the repository due to size. Place `tokopedia_products_with_review.csv` in the root directory before training.

---

## üõ†Ô∏è Tech Stack

| Category           | Technologies                |
| ------------------ | --------------------------- |
| **ML Framework**   | LightGBM, scikit-learn      |
| **Explainability** | SHAP                        |
| **API**            | FastAPI, Pydantic           |
| **Dashboard**      | Streamlit, Plotly           |
| **Data**           | Pandas, NumPy               |
| **Monitoring**     | Custom metrics, scipy stats |

---

## üìù License

This project is licensed under the MIT License.

---

## üë§ Author

**Muneeb MM**

- GitHub: [@MuneebMM](https://github.com/MuneebMM)

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request
